{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predilex\n",
    "\n",
    "NLP appliqué à l'analyse de décisions juridiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "Suite à un accident on peut avoir les étapes suivantes:\n",
    "- date de l'accident\n",
    "- date de déclaration du sinistre\n",
    "- date de consolidation (la consolidation correspond à la stabilisation de l’état de santé après un accident)\n",
    "- date de décision judicière d'indemnisation lorsque l'assurance et la victime ne se mettent pas d'accord sur le montant\n",
    "\n",
    "Le but est de trouver le sexe de la victime, date de l'accident et la date de consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texte de jurisprudence\n",
    "\n",
    "Construction du texte de jurisprudence:\n",
    "- Identification de la décision\n",
    "- Partie appelante\n",
    "- Partie intimée\n",
    "- Composition de la cour\n",
    "- Exposé des faits\n",
    "- Motif de l'arrêt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_train\n",
    "Les informations que l'on cherche à rencenser:\n",
    "- sexe de la victime\n",
    "- date de l'accident\n",
    "- date de consolidation\n",
    "\n",
    "Typologies de dates:\n",
    "- n.c. : non communiquée\n",
    "- n.a. : non applicable (en cas de décès)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première approche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des fichiers d'un répertoire `scandir()`\n",
    "Lecture des fichiers textes https://realpython.com/working-with-files-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agen_2118.txt\n",
      "Agen_100515.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# List all files in a directory using scandir()\n",
    "basepath = './data/dev/txt_files/'\n",
    "with os.scandir(basepath) as entries: # renvoie un itérateur\n",
    "    for entry in entries:\n",
    "        if entry.is_file():\n",
    "            print(entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du début d'un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le : 12/11/2019\n",
      " \n",
      " \n",
      "Cour d’appel d’Agen \n",
      " \n",
      "Audience publique du 20 août 2003 \n",
      " \n",
      "N° de RG: 02/118 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_name = 'Agen_2118.txt'\n",
    "with open(os.path.join(basepath, file_name)) as f:\n",
    "    print(f.read(100))\n",
    "    #print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction du sexe de la victime \n",
    "Approche naïve en prédisant le sexe de la victime via le décompte de mots-clés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation du document en sac de mots (BOW)\n",
    "Version simplifiée: on fait une première segmentation (`tokenizer`) en séparant sur les espaces.  \n",
    "On place ensuite les mots dans un dictionnaire `frequency` du type {mot:fréquence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = {}\n",
    "with open(os.path.join(basepath, file_name)) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if word in frequency:\n",
    "                frequency[word] += 1\n",
    "            else:\n",
    "                frequency[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency['il']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency['elle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur un exemple notre algorithme se trompe, il va falloir faire les tests sur les ensembles `train` et `test` pour voir ce que ça donne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problème de notre segmenteur: beaucoup de \"mots\" n'en sont pas de véritables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency['02/118']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il va falloir utiliser des expressions régulières pour affiner notre algorithme.  \n",
    "https://regexr.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit3a3ee49f54404a33b933719135399d37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
